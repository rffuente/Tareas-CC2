{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> ILI286 - Computación Científica II  </h1>\n",
    "    <h2> Valores y Vectores Propios </h2>\n",
    "    <h2> [S]cientific [C]omputing [T]eam<sup>1</sup></h2>\n",
    "</center>\n",
    "\n",
    "  \n",
    "<br>\n",
    "<br>\n",
    "[1] _Material creado por profesor Claudio Torres_ (`ctorres@inf.utfsm.cl`) _y ayudantes: Alvaro Salinas y Martín Villanueva. DI UTFSM. Abril 2016._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### DISCLAIMER ###\n",
    "\n",
    "El presente notebook ha sido creado para el curso **ILI286 - Computación Científica 2**, del [Departamento de Informática](http://www.inf.utfsm.cl/), [Universidad Técnica Federico Santa María](http://www.utfsm.cl/). \n",
    "\n",
    "El material ha sido creado por Claudio Torres <ctorres@inf.utfsm.cl> y Sebastian Flores <sebastian.flores@usm.cl>, y es distribuido sin restricciones. En caso de encontrar un error, por favor no dude en contactarnos.\n",
    "\n",
    "[Update 2015] Se ha actualizado los notebooks a Python3 e includio el \"magic\" \"%matplotlib inline\" antes de cargar matplotlib para que los gráficos se generen en el notebook. \n",
    "\n",
    "[Updata 2016] (Martín) Modificaciones mayores al formato original. Agregado contexto: Introducción, marco teórico, explicaciones y tareas. Modificaciones menores en los algoritmos. Agregada la sección de Problema de Aplicación.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de Contenidos\n",
    "* [Introducción](#intro)\n",
    "* [Marco Teórico](#teo)\n",
    "* [Algoritmos e Implementaciones](#alg)\n",
    "    * [Power Iteration](#pi)\n",
    "    * [Inverse Power Iteration](#invpi)\n",
    "    * [Rayleigh Quotient Iteration](#rq)\n",
    "    * [SciPy Eigenvalue](#sp)\n",
    "    * [Problema de Aplicación](#problema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro' />\n",
    "# Introducción\n",
    "\n",
    "Determinar los valores y vectores propios de una matriz, aporta gran información acerca de las características y propiedades de esta, como también posee gran cantidad de aplicaciones prácticas como: Análisis de convergencia de sistemas dinámicos, PCA (Principal Component Analysis), análisis espectral, Eigenfaces, etc.\n",
    "\n",
    "Sin embargo la determinación de los valores y vectores propios no es un problema simple. Como ya debe haber estudiado en cursos anteriores, existe un método directo basado en cálculo de las raíces del polinomio característico $p(x)$. Pero este problema resulta ser _mal condicionado_, esto es, a pequeñas variaciones en la matriz $A$ original, existe una gran variación en los resultados de los valores y vectores propios obtenidos (Ver polinomio de Wilkinson, texto guia).\n",
    "\n",
    "En este notebook estudiaremos un método iterativo conocido como _Power Iteration_ (y sus extensiones), que de modo similar a una iteración de punto fijo, permite obtener numéricamente los eigen(valores/vectores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='teo' />\n",
    "# Marco Teórico\n",
    "\n",
    "La motivación tras PI (Power Iteration) es que la multiplicación por matrices, tiende a \"dirigir\" a los vectores hacia el vector propio dominante (aquel con valor propio de mayor magnitud).\n",
    "\n",
    "El algoritmo en cuestión es como sigue:\n",
    "\n",
    "```python\n",
    "x = 'Initial guess'\n",
    "for i in range n_iter:\n",
    "    u = x / ||x||             #normalization step\n",
    "    x = dot(A,u)              #power iteration step\n",
    "    lamb = dot(u, dot(A, u))  #Rayleigh quotient\n",
    "return x / ||x||\n",
    "```\n",
    "\n",
    "en donde se agrega una paso de _normalización_, para evitar que la magnitud del vector aumente sin límite, y el valor propio asociado se obtiene por medio del cociente de Rayleigh:\n",
    "\n",
    "$$ \\lambda = \\frac{x^T A x}{x^T x} $$\n",
    "\n",
    "Para entender porque se de esta convergencia, considere una matriz $A \\in \\mathbb{R}^{m \\times m}$ con valores propios reales $\\lambda_1, \\lambda_2, \\ldots, \\lambda_m$ tales que $|\\lambda_1| > |\\lambda_2| \\geq |\\lambda_3| \\geq \\ldots \\geq |\\lambda_m|$, tales que los vectores propios $\\{v_1, v_2, \\ldots, v_m \\}$ conforman una base de $\\mathbb{R}^m$. Sea entonces $x_0$ el _initial guess_, este puede ser expresado como una combinación lineal de los vectores propios $v_k$:\n",
    "\n",
    "\\begin{align}\n",
    "A x_0 &= c_1 A v_1 + \\cdots + c_m A v_m = c_1 \\lambda_1 v_1 + \\cdots + c_m \\lambda_m v_m \\\\\n",
    "A^2 x_0 & = c_1 \\lambda_1 A v_1 + \\cdots + c_m \\lambda_m A v_m = c_1 \\lambda_1^2 v_1 + \\cdots + c_m \\lambda_m^2 v_m \\\\\n",
    "\\vdots &= \\vdots \\\\\n",
    "A^k x_0 &= c_1 \\lambda_1^k v_1 + \\cdots + c_m \\lambda_m^k v_m\n",
    "\\end{align}\n",
    "\n",
    "Factorizando $\\lambda_1^k$ del último resultado se obtiene:\n",
    "\n",
    "$$ \\frac{A^k x_0}{\\lambda_1^k} = c_1 v_1 + c_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k v_2 + \\cdots + c_m \\left(\\frac{\\lambda_m}{\\lambda_1}\\right)^k v_m$$\n",
    "\n",
    "Dado que $|\\lambda_1|>|\\lambda_i| \\ \\ \\forall i \\neq 1$, a medida que $k \\rightarrow \\infty$ todos los términos excepto el primero tienden a cero, con razón de convergencia $S \\leq |\\lambda_2/\\lambda_1|$. Obteniendo como resultado un vector que es múltiplo del vector propio dominante.\n",
    "\n",
    "**Nota**: Para más detalles revisar: _Numerical Analysis, Tymothy Sauer, Chapter 12: Eigenvalues and Singular Values_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='alg' />\n",
    "# Algoritmos e Implementaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías utilizadas durante la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import norm, solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz y vector de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[  1.    0.5  -0.1]\n",
      " [  0.5   1.   10. ]\n",
      " [  2.    3.    5. ]]\n",
      "x = [ 1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 0.5],[0.5, 1]])\n",
    "x = np.array([1.,0.])\n",
    "A = np.array([[1., 0.5,-0.1],[0.5, 1.,10.0],[2.,3.,5.]])\n",
    "x = np.array([1.,0.,0.])\n",
    "print(\"A =\\n\",A)\n",
    "print(\"x =\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='pi' />\n",
    "## Power Iteration \n",
    "A continuación se entrega el código del algoritmo clásico de Power Iteration. Pruebe cambiando las matrices y los parámetros del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def power_iteration(A, x, k, verbose=False):\n",
    "    \"\"\"\n",
    "    Program 12.1 Power iteration\n",
    "    Computes dominant eigenvector of square matrix\n",
    "    Input: matrix A, initial (nonzero) vector x, number of steps k\n",
    "    Output: dominant eigenvalue lam, eigenvector u\n",
    "    \"\"\"\n",
    "    if verbose: print(\"Power Iteration Method\\n%s\"%('='*80))\n",
    "    for j in range(k):\n",
    "        u = x/norm(x)\n",
    "        x = np.dot(A, u)\n",
    "        lam = np.dot(u, x) #not really necessary to compute it at each iteration\n",
    "        if verbose: print(\"k=%d, lambda=%+.3f, u=%s\"%(j,lam,str(u.T)))\n",
    "    u = x/norm(x)\n",
    "    if verbose: print(\"k=%d, lambda=%+.3f, u=%s\\n\"%(j+1,lam,str(u.T)))\n",
    "    return (lam, u)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power Iteration Method\n",
      "================================================================================\n",
      "k=0, lambda=+1.000, u=[ 1.  0.  0.]\n",
      "k=1, lambda=+7.343, u=[ 0.43643578  0.21821789  0.87287156]\n",
      "k=2, lambda=+8.149, u=[ 0.04202177  0.84043546  0.54027994]\n",
      "k=3, lambda=+9.162, u=[ 0.04966055  0.76207029  0.6455871 ]\n",
      "k=4, lambda=+8.861, u=[ 0.03992439  0.78976799  0.61210503]\n",
      "k=5, lambda=+8.861, u=[ 0.04215815  0.78209453  0.62173213]\n",
      "\n",
      "lambda = 8.861125789948249\n",
      "v (dominant eigenvector) = [ 0.04215815  0.78209453  0.62173213]\n"
     ]
    }
   ],
   "source": [
    "# Testing algorithm\n",
    "lam, u = power_iteration(A, x, 5, verbose=True)\n",
    "print(\"lambda = {0}\".format(lam))\n",
    "print(\"v (dominant eigenvector) = {0}\".format(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='invpi' />\n",
    "## Inverse Power Iteration\n",
    "\n",
    "Una de las complicaciones que tiene el algoritmo anterior, es que sólo permite encontrar el valor y vectores propios dominantes. Luego ¿Cómo encontramos el resto?. Para responder esta pregunta, es necesario examinar dos propiedades importantes:\n",
    "\n",
    "1. Los valores propios de la matriz inversa $A^{-1}$ son los recíprocos de los valores propios de $A$, es decir: $\\lambda_1^{-1}, \\lambda_2^{-1}, \\ldots , \\lambda_m^{-1}$. Los vectores propios de se mantienen inalterados.\n",
    "2. Los valores propios de la matriz con _shift_ $A - sI$ son: $\\lambda_1-s, \\lambda_2-s, \\ldots, \\lambda_m-s$. Del mismo modo, los vectores propios se mantienen inalterados.\n",
    "\n",
    "**Tarea**: Pruebe estas propiedades!\n",
    "\n",
    "La idea es entonces realizar un shift $\\widetilde{s}$ cercano a algún valor propio $s_k$, y computar PI sobre $(A - \\widetilde{s}I)^{-1}$. Luego:\n",
    "\n",
    "$$ |\\lambda_k - \\widetilde{s}| < |\\lambda_i - \\widetilde{s}| \\leftrightarrow  \\bigg| \\frac{1}{\\lambda_k - \\widetilde{s}} \\bigg| > \\bigg| \\frac{1}{\\lambda_i - \\widetilde{s}} \\bigg| \\ \\ \\forall i \\neq k \\ $$\n",
    "\n",
    "entonces $\\frac{1}{\\lambda_k - \\widetilde{s}}$ corresponderá con el vector propio dominante de $(A - \\widetilde{s}I)^{-1}$. Notar que por lo enunciado en las propiedades, los vectores propios se mantienen sin alteraciones.\n",
    "\n",
    "La idea anterior se ve reflejada en el algoritmo implementado a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inverse_power_iteration(A, x, s, k, verbose=False):\n",
    "    \"\"\"\n",
    "    Program 12.2 Inverse Power iteration\n",
    "    Computes eigenvector of square matrix nearest to input s\n",
    "    Input: matrix A, initial (nonzero) vector x, shift s, number of steps k\n",
    "    Output: dominant eigenvalue lam, eigenvector of inv(A-sI)\n",
    "    \"\"\"\n",
    "    if verbose: print(\"Inverse Power Iteration Method\\n%s\"%('='*80))\n",
    "    As = A - s*np.eye(*A.shape)\n",
    "    for j in range(k):\n",
    "        u = x/norm(x)\n",
    "        x = solve(As, u)\n",
    "        lam = np.dot(u.T, x)\n",
    "        if verbose: print(\"k=%d, lambda=%+.3f, u=%s\"%(j,1./lam+s,str(u.T)))\n",
    "    u = x/norm(x)\n",
    "    if verbose: print(\"k=%d, lambda=%+.3f, u=%s\\n\"%(j+1,1./lam+s,str(u.T)))\n",
    "    return (1./lam+s, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse Power Iteration Method\n",
      "================================================================================\n",
      "k=0, lambda=+0.667, u=[ 1.  0.  0.]\n",
      "k=1, lambda=+0.708, u=[ 0.83205029 -0.5547002   0.        ]\n",
      "k=2, lambda=+0.689, u=[ 0.85215434 -0.5224972  -0.02880359]\n",
      "k=3, lambda=+0.692, u=[ 0.84821173 -0.52903451 -0.02567759]\n",
      "k=4, lambda=+0.692, u=[ 0.84877374 -0.52810527 -0.02622915]\n",
      "k=5, lambda=+0.692, u=[ 0.84868498 -0.52825191 -0.02614794]\n",
      "k=6, lambda=+0.692, u=[ 0.84869852 -0.52822953 -0.02616062]\n",
      "k=7, lambda=+0.692, u=[ 0.84869643 -0.52823299 -0.02615868]\n",
      "k=8, lambda=+0.692, u=[ 0.84869675 -0.52823246 -0.02615898]\n",
      "k=9, lambda=+0.692, u=[ 0.84869671 -0.52823254 -0.02615893]\n",
      "k=10, lambda=+0.692, u=[ 0.84869671 -0.52823252 -0.02615894]\n",
      "\n",
      "lambda = 0.6918800781738075\n",
      "v = [ 0.84869671 -0.52823252 -0.02615894]\n"
     ]
    }
   ],
   "source": [
    "# Testing algoritm\n",
    "lam, u = inverse_power_iteration(A, x, s=1./4, k=10, verbose=True)\n",
    "print(\"lambda = {0}\".format(lam))\n",
    "print(\"v = {0}\".format(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='rq' />\n",
    "## Rayleigh Quotient Iteration\n",
    "\n",
    "Como se analizó anteriormente, PI e _Inverse_ PI tienen convergencia lineal con razón de convergencia $S \\approx \\frac{\\lambda_2}{\\lambda_1}$. Además sabemos que _Inverse_ PI converge hacia el valor propio más cercano al shift, y que mientras más cercano sea el shift a tal valor, más rápido se logra la convergencia.\n",
    "\n",
    "Entonces la idea de RQI es la siguiente: Si en cada iteración se tiene una aproximación del valor propio que andamos buscando, podemos ocupar esta aproximación como shift $s$, y dado que el shift será más cercano al valor propio, se acelerará la convergencia.\n",
    "\n",
    "Tal valor aproximado es obtenido con el cociente de Rayleigh, y entonces el shift es actualizado con este cociente en cada iteración. Como resultado se produce el siguiente _trade-off_:\n",
    "\n",
    "1. La convergencia pasa a ser cuadrática (de modo general) y cúbica para matrices simétricas.\n",
    "2. Sin embargo, se paga el costo de tener que resolver un sistema de ecuaciones diferentes en cada iteración.\n",
    "\n",
    "\n",
    "A continuación se presenta una implementación del RQI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rqi(A, x, k, verbose=False):\n",
    "    \"\"\"\n",
    "    Program 12.3 Rayleigh Quotient Iteration\n",
    "    Input: matrix A, initial (nonzero) vector x, number of steps k\n",
    "    Output: eigenvalue lam, eigenvector of inv(A-sI)\n",
    "    \"\"\"\n",
    "    if verbose: print(\"Rayleigh Quotient Iteration\\n%s\"%('='*80))\n",
    "    for j in range(k):\n",
    "        u = x/norm(x)\n",
    "        lam = np.dot(u.T, np.dot(A, u))\n",
    "        try:\n",
    "            x = solve(A -lam*np.eye(*A.shape), u)\n",
    "        except numpy.linalg.LinAlgError:\n",
    "            break\n",
    "        if verbose: print(\"k=%d, lambda=%+.3f, u=%s\"%(j,lam,str(u.T)))\n",
    "    u = x/norm(x)\n",
    "    lam = float(np.dot(u.T, np.dot(A, u)))\n",
    "    if verbose: print(\"k=%d, lambda=%+.3f, u=%s\\n\"%(j+1,lam,str(u.T)))\n",
    "    return (lam, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas:** \n",
    "1. ¿Porque es necesario el `try` y `except` en las líneas 11 y 13? ¿Que significa que el sistema no pueda ser resuelto?\n",
    "2. Como puede observar RQI no recibe shift como parámetro. ¿A cuál valor/vector propio convergerá? ¿Como forzar/guiar a que tienda hacia un valor/vector propio distinto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.6932112420074121\n",
      "v = [ 0.84904794 -0.52765648 -0.02638637]\n"
     ]
    }
   ],
   "source": [
    "# Testing algorithm\n",
    "lam, v = rqi(A, x, k=2)\n",
    "print(\"lambda = {0}\".format(lam))\n",
    "print(\"v = {0}\".format(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='sp' />\n",
    "## $\\texttt{SciPy}$ Eigenvalue\n",
    "La librería scipy tiene implementados algoritmos que permite calcular los valores y vectores propios. Las opciones posibles son:\n",
    "\n",
    "  - En la librería scipy.linalg: eigvals/eigvalsh/eigvals_banded, eig/eigh/eig_banded,\n",
    "\n",
    "  - En la librería scipy.sparse.linalg: eigen, eigs, eigsh.\n",
    " \n",
    "En general siempre conviene utilizar las funciones desde scipy y no de numpy. La librería numpy hace un excelente trabajo al permitir el uso de vectores de tipo numérico, pero contiene solo algunos algoritmos numéricos y no necesariamente los más rápidos.\n",
    "\n",
    "A continuación se muestra como utilizar algunas de estas funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.90626230+0.j -0.79046718+0.j  0.07215956+0.j]\n",
      "********************************************************************************\n",
      "[-0.79046718  0.07215956  2.9062623 ]\n",
      "********************************************************************************\n",
      "(array([ 2.90626230+0.j, -0.79046718+0.j,  0.07215956+0.j]), array([[-0.57957665, -0.72520493, -0.37171053],\n",
      "       [-0.5510755 ,  0.68480959, -0.47681403],\n",
      "       [-0.60033882,  0.07150972,  0.79654232]]))\n",
      "********************************************************************************\n",
      "(array([-0.79046718,  0.07215956,  2.9062623 ]), array([[ 0.72520493, -0.37171053, -0.57957665],\n",
      "       [-0.68480959, -0.47681403, -0.5510755 ],\n",
      "       [-0.07150972,  0.79654232, -0.60033882]]))\n",
      "********************************************************************************\n",
      "-0.790467175639\n",
      "[ 0.72520493 -0.68480959 -0.07150972]\n",
      "[-0.57325069  0.5413195   0.05652608]\n",
      "[-0.57325069  0.5413195   0.05652608]\n"
     ]
    }
   ],
   "source": [
    "# Full matrices\n",
    "from scipy import linalg as LA\n",
    "N = 3\n",
    "Aux = np.random.rand(N,N)\n",
    "A = Aux + Aux.T # symmetric, so we'll deal with real eigs.\n",
    "print(LA.eigvals(A)) # Only the eigenvalues, A not necessarily symmetric\n",
    "print(\"*\"*80)\n",
    "print(LA.eigvalsh(A)) # Only the eigenvalues, A symmetric \n",
    "print(\"*\"*80)\n",
    "print(LA.eig(A))     # All the eigenvalues and eigenvectors, A not necessarily symmetric\n",
    "print(\"*\"*80)\n",
    "print(LA.eigh(A))    # All the eigenvalues and eigenvectors, A symmetric (faster)\n",
    "print(\"*\"*80)\n",
    "lambdas, V = LA.eigh(A)    # All the eigenvalues and eigenvectors, A symmetric (faster)\n",
    "l1 = lambdas[0]\n",
    "v1 = V[:,0]\n",
    "print(l1)\n",
    "print(v1)\n",
    "print(np.dot(A, v1))\n",
    "print(l1*v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='problema' />\n",
    "## Problema de Aplicación\n",
    "\n",
    "Las matrices simétricas tiene una propiedad muy interesante:\n",
    "\n",
    "* Los vectores propios de las matrices simétricas son ortogonales entre sí.\n",
    "\n",
    "En base a lo anterior se propone el siguiente algoritmo para encontrar los primeros $k$ valores/vectores propios:\n",
    "\n",
    "```python\n",
    "def kEigenFinder(A, k, p):\n",
    "    m = A.shape[0]\n",
    "    lamb = 0.\n",
    "    v = np.zeros((m,1))\n",
    "    Lamb = []\n",
    "    V = []\n",
    "    for i in range(k):\n",
    "        A -= lamb*np.dot(v,v.T)\n",
    "        lamb,v = power_iteration(A, p)\n",
    "        Lamb.append(lamb)\n",
    "        V.append(v)\n",
    "    return Lamb,V    \n",
    "```\n",
    "\n",
    "1. Justifique la validez de tal procedimiento.\n",
    "2. Construya una matriz simétrica de $100 \\times 100$ y ejecute el `kEigenFinder` sobre tal matriz. Una forma fácil de construir una matriz simétrica es la [matriz de covarianza](https://en.wikipedia.org/wiki/Covariance_matrix):\n",
    "$$\\Sigma_X = \\frac{1}{n-1}X^T X$$\n",
    "donde $X \\in \\mathbb{R}^{m \\times n}$, con $m$ _samples_ y $n$ _features_.\n",
    "\n",
    "3. Concluya acerca de la utilidad del procedimiento propuesto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25  0.    0.5   1.  ]\n",
      " [ 0.25  0.    0.5   0.  ]\n",
      " [ 0.25  0.    0.    0.  ]\n",
      " [ 0.25  1.    0.    0.  ]]\n",
      "Power Iteration Method\n",
      "================================================================================\n",
      "k=0, lambda=+0.250, u=[ 1.  0.  0.  0.]\n",
      "k=1, lambda=+1.000, u=[ 0.5  0.5  0.5  0.5]\n",
      "k=2, lambda=+0.988, u=[ 0.76376262  0.32732684  0.10910895  0.54554473]\n",
      "k=3, lambda=+0.990, u=[ 0.79459511  0.24659848  0.19179882  0.52059679]\n",
      "k=4, lambda=+0.972, u=[ 0.8196961   0.29619271  0.19975787  0.44773316]\n",
      "k=5, lambda=+0.972, u=[ 0.77114178  0.31233889  0.20999055  0.51350631]\n",
      "\n",
      "lambda = 0.9724330992598218\n",
      "v (dominant eigenvector) = [ 0.77114178  0.31233889  0.20999055  0.51350631]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0.25,0.25,0.25,0.25],[0,0,0,1],[0.5,0.5,0,0],[1,0,0,0]])\n",
    "B = A.transpose()\n",
    "print(B)\n",
    "y = np.array([1.,0.,0.,0.]) \n",
    "lam,u = power_iteration(B,y,5,verbose=True)\n",
    "print(\"lambda = {0}\".format(lam))\n",
    "print(\"v (dominant eigenvector) = {0}\".format(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-3469a651c7d1>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-3469a651c7d1>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    lam = np.dot(u, x) #not really necessary to compute it at each iteration\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0.25,0.25,0.25,0.25],[0,0,0,1],[0.5,0.5,0,0],[1,0,0,0]])\n",
    "B = A.transpose()\n",
    "print(B)\n",
    "y = np.array([1.,0.,0.,0.]) \n",
    "m,v = power_iteration(B,y,5,verbose=True)\n",
    "print(\"lambda = {0}\".format(lam))\n",
    "print(\"v (dominant eigenvector) = {0}\".format(u))\n",
    "def power_iteration_2(A, x, k, verbose=False,m,v):\n",
    "    \"\"\"\n",
    "    Program 12.1 Power iteration\n",
    "    Computes dominant eigenvector of square matrix\n",
    "    Input: matrix A, initial (nonzero) vector x, number of steps k\n",
    "    Output: dominant eigenvalue lam, eigenvector u\n",
    "    \"\"\"\n",
    "    if verbose: print(\"Power Iteration Method\\n%s\"%('='*80))\n",
    "    for j in range(k):\n",
    "        u = x/norm(x)\n",
    "        x = np.dot((A-m*np.dot(v,v.transpose()), u)\n",
    "        lam = np.dot(u, x) #not really necessary to compute it at each iteration\n",
    "        if verbose: print(\"k=%d, lambda=%+.3f, u=%s\"%(j,lam,str(u.T)))\n",
    "    u = x/norm(x)\n",
    "    if verbose: print(\"k=%d, lambda=%+.3f, u=%s\\n\"%(j+1,lam,str(u.T)))\n",
    "    return (lam, u) \n",
    "power_iteration_2(B,y,5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
